# **운영체제**

## **운영체제란?**

컴퓨터 하드웨어가 컴퓨터 소프트웨어와 통신하고 작동하도록하는 소프트웨어 프로그램

## **운영체제의 목적**

1. 컴퓨터 시스템의 계산 활동을 관리하여 컴퓨터 시스템이 제대로 작동하도록 한다.

2. 프로그램 개발 및 실행을 위한 환경을 제공한다.

## **시스템 콜이란?**

시스템콜은 커널과 사용자 사이의 인터페이스 역할을 하는 것으로 **쉘(Shell)**에서 명령어나 서브루틴 형식으로 운영체제의 기능을 호출할 수 있다. 즉, 사용자가 직접 커널에 접근할 수 없기 때문에 시스템콜을 활용해야한다.

보통 시스템 콜을 직접 사용하기보다는, 해당 시스템 콜을 사용해서 만든 각 언어별 라이브러리(API)를 사용한다.

쉽게 말하면 **운영체제의 기능을 호출하는 함수**이다.

## **커널이란?**

운영체제의 핵심적인 부분으로, 파일입출력, 프로세스관리 등과 같이 **운영체제의 기능을 담당**하지만 일반 사용자모드에선 커널에 접근할 수 없기 때문에 원칙적으로는 파일 입출력, 프로세스 생성등 커널의 기능을 사용하지 못한다. 그래서 운영체제에서 제공하는 것이 **시스템 콜**이다.

응용프로그램이 운영체제의 기능을 요청하기 위해서, 운영체제는 **시스템 콜**을 제공한다. (시스템 함수를 호출하는 것이어서 시스템 콜, 운영체제가 제공하는 기능을 사용할 수 있는 api)

## **쉘(Shell)이란?**

운영체제는 쉘을 통해서 사용자 인터페이스를 제공한다.쉘은 사용자가 운영체제 기능과 서비스를 조작할 수 있도록 **인터페이스를 제공하는 프로그램**이다.쉘은 터미널환경(CLI)과 GUI 환경 두 종류로 나뉜다.

## **Byte Ordering이란 ?**

Byte Ordering이란 데이터가 저장되는 순서를 의미합니다. 

Byte Ordering의 방식에는 빅엔디안(Big Endian)과 리틀엔디안(Little Endian)이 있습니다.

- Big Endian
- MSB가 가장 낮은 주소에 위치하는 저장 방식네트워크에서 데이터를 전송할 때 주로 사용됨가장 낮은 주소에 MSB가 저장되므로, offset=0인 Byte를 보면 양수/음수를 바로 파악할 수 있다.
- Little Endian
- MSB가 가장 높은 주소에 위치하는 방식마이크로프로세서에서 주로 사용된다. 가장 낮은 주소에 부호값이 아닌 데이터가 먼저 오기 때문에, 바로 연산을 할 수 있다.

## **프로세스란?**

컴퓨터에서 실행되고 있는 프로그램을 프로세스라고 한다.

두 가지 유형의 프로세스가 있다. 운영 체제 프로세스, 사용자 프로세스

## **프로세스의 특징**

- 프로세스는 각각 독립된 메모리 영역(Code, Data, Stack, Heap의 구조)을 할당받는다.
- 기본적으로 프로세스당 최소 1개의 스레드(메인 스레드)를 가지고 있다.
- 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없다.
- 한 프로세스가 다른 프로세스의 자원에 접근하려면 프로세스 간의 통신(IPC, inter-process communication)을 사용해야 한다. (Ex. 파이프, 파일, 소켓 등을 이용한 통신 방법 이용)

## **IPC (InterProcess Communication)**

프로세스는 독립적으로 실행된다. 독립되어있다는 것은 다른 프로세스에게 영향을 받지 않는다는 것 (메모리공간이 독립되어있다. 스레드는 프로세스 안에서 자원을 공유하므로 다른 스레드의 영향을 받는다.)

이런 독립적 구조를 가진 **프로세스간의 통신**을 해야하는 상황이 있을 것이다. 이를 가능하도록 해주는 것이 바로 IPC 통신이다.

프로세스는 **커널**이 제공하는 IPC 설비를 이용해 프로세스간 통신을 할 수 있다.

## **스레드(Thread)란?**

스레드는 CPU 사용의 기본 단위이다. 프로세스 내에서 실행되는 여러 흐름의 단위를 말한다.

스레드는 스레드 ID, 프로그램 카운터, 레지스터 세트 및 스택으로 구성된다.

[참고] 운영체제는 자원을 효율적으로 사용하려고 한다. 스레드를 사용하면 프로세스보다 생성할 때 오버헤드도 적고 공유된 자원에 대해서도 오버헤드가 적다. 그리고 스레드를 이용하면 병렬성을 높일 수 있다.

## **스레드의 특징**

- 스레드는 프로세스 내에서 각각 Stack만 따로 할당받고 Code, Data, Heap 영역은 공유한다.
- 프로세스 내의 주소 공간이나 자원들(힙 공간 등)을 같은 프로세스 내에 스레드끼리 공유하면서 실행된다.
- 같은 프로세스 안에 있는 여러 스레드들은 같은 힙 공간을 공유한다. 반면에 프로세스는 다른 프로세스의 메모리에 직접 접근할 수 없다.
- 각각의 스레드는 별도의 레지스터와 스택을 갖고 있지만, 힙 메모리는 서로 읽고 쓸 수 있다.
- 한 스레드가 프로세스 자원을 변경하면, 다른 이웃 스레드(sibling thread)도 그 변경 결과를 즉시 볼 수 있다.

## **프로세스와 스레드의 차이**

프로세스는 운영체제로부터 자원을 할당받는 작업의 단위이고, 스레드는 프로세스가 할당받은 자원을 이용하는 실행의 단위 이다. 프로세스는 운영체제로부터 메모리, 주소 공간 등을 할당받고 쓰레드는 할당받은 자원들을 내부 스레드끼리 공유하면서 실행된다.

[정리]

- 프로세스는 실행 중인 프로그램으로 다른 프로세스와 상관없이 독립적으로 자원을 할당 받는다.
- 스레드는 경량화된 프로세스로 프로세스 안에 존재한다. 각 스레드는 별도의 레지스터와 스택을 갖고, 힙 영역은 공유한다.

스레드를 사용하는 이유는 운영체제에서 더 효율적으로 시스템 자원을 관리하기 위해 사용된다고 할 수 있다. 멀티 프로세스로 진행되는 작업을 멀티 쓰레드로 수행하게 되면 시스템 콜이 줄어들기 때문에, 자원을 효율적으로 관리 할 수 있고 프로세스의 통신비용보다 쓰레드간의 통신 비용이 적다는 이점도 있다.

단 스레드간의 자원공유는 전역변수를 이용하므로 동기화 문제에 신경을 써야하며 멀티스레드 프로그래밍은 프로그래머의 주의를 요구한다.

![https://velog.velcdn.com/images%2Fsyleemk%2Fpost%2Fff7b9fa7-5af5-4e0c-9f17-8d399531d78b%2Fimage.png](https://velog.velcdn.com/images%2Fsyleemk%2Fpost%2Fff7b9fa7-5af5-4e0c-9f17-8d399531d78b%2Fimage.png)

## **스레드의 장점**

- 스레드는 프로세스보다 생성 및 종료시간, 스레드간 전환시간이 짧다.
- 스레드는 프로세스의 메모리, 자원등을 공유하므로 커널의 도움없이 상호간의 통신이 가능하다.

## **멀티 스레딩(Multi-threading) 의 장점과 단점**

- 멀티 스레딩이란 하나의 프로세스를 다수의 스레드로 만들어 실행하는 것

장점)

- 하나의 프로세스 내에 다수의 실행 단위들이 존재하여 작업의 수행에 필요한 자원들을 공유하기 때문에 자원의 생성과 관리가 중복되는 것을 줄일 수 있다.
- 문맥 전환이 빠르다는 장점

단점)

- 교착상태를 발생시킬 수 있다.
- 동기화에 주의해야한다.

## **멀티 쓰레드의 동시성과 병렬성**

- 동시성은멀티 작업을 위해 싱글 코어에서 여러 개의 쓰레드가 번갈아 실행하는 것을 말합니다.(동시에 실행하는 것처럼 보이지만 사실은 번갈아가며 실행하고 있는 것임)
- 병렬성은 멀티 작업을 위해 멀티 코어에서 한 개 이상의 쓰레드를 포함하는 각 코어들을 동시에 실행하는 것을 말합니다.

## **멀티 프로세스 대신 멀티 스레드를 사용하는 이유**

- 쉽게 설명하면, 프로그램을 여러 개 키는 것보다 하나의 프로그램 안에서 여러 작업을 해결하는 것이다.
- 자원의 효율성 증대
    - 멀티 프로세스로 실행되는 작업을 멀티 스레드로 실행할 경우, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있다. (프로세스 간의 Context Switching시 단순히 CPU 레지스터 교체 뿐만 아니라 RAM과 CPU 사이의 캐시 메모리에 대한 데이터까지 초기화되므로 오버헤드가 크기 때문)
    - 스레드는 프로세스 내의 메모리를 공유하기 때문에 독립적인 프로세스와 달리 스레드 간 데이터를 주고받는 것이 간단해지고 시스템 자원 소모가 줄어들게 된다.
- 처리 비용 감소 및 응답 시간 단축
    - 프로세스 간의 통신(IPC)보다 스레드 간의 통신의 비용이 적으므로 작업들 간의 통신의 부담이 줄어든다. (스레드는 Stack 영역을 제외한 모든 메모리를 공유하기 때문)
    - 프로세스 간의 전환 속도보다 스레드 간의 전환 속도가 빠르다. (Context Switching시 스레드는 Stack 영역만 처리하기 때문)

## **문맥 교환(Context Switching)이란?**

프로세스 상태를 변경하는 것을 말한다. 하나의 프로세스가 CPU를 사용 중인 상태에서 다른 프로세스가 CPU를 사용하도록 하기 위해 이전 프로세스의 상태를 보관하고 새로운 프로세스의 상태를 적재하는 작업이다. 즉, 스케줄링에 의해 실행 중인 코드, 자원 등을 저장하고 현재 상태를 대기 상태로 만들고, 다른 프로세스를 실행시키는 과정

## **멀티 프로세싱과 멀티프로그래밍의 차이**

멀티 프로세싱은 여러개의 처리장치(CPU)를 장착하여 동시에 여러 작업을 병렬로 실행하는 방법.

멀티 프로그래밍은 다수 개의 프로그램의 같이 주기억장치에 있도록 한 방식.

## **CPU 스케줄링**

CPU를 잘 사용하기 위해 프로세스를 잘 배정하는 것, OS에 의해 일어남

- 조건 : 오버헤드 줄이고 / CPU사용률 높이고 / 기아현상 줄이고
- 목표
    - 배치 시스템 : 가능하면 많은 일을 수행, 시간보단 처리량(throughout)이 중요
    - interactive system : 빠른 응답시간, 적은 대기시간
    - real-time system : 기한(deadline)까지 맞추기

## **선점 / 비선점 스케줄링**

- 선점 (preemptive) : OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우
- 비선점 (nonpreemptive) : 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리시간 예측 어렵다)

![https://velog.velcdn.com/images%2Fsyleemk%2Fpost%2Faa894f50-1518-42cf-b6ce-0aed20ff26c8%2Fimage.png](https://velog.velcdn.com/images%2Fsyleemk%2Fpost%2Faa894f50-1518-42cf-b6ce-0aed20ff26c8%2Fimage.png)

- 비선점 스케줄링 : `Interrupt`, `Scheduler Dispatch`
- 선점 스케줄링 : `I/O or Event wait`

### **프로세스 상태 전이**

- 승인 (Admitted) : 프로세스 생성이 가능하여 승인됨
- 스케줄러 디스패치 (Scheduler Dispatch) : 준비상태에 있는 프로세스중 하나를 선택하여 실행시키는 것
- 인터럽트 (Interrupt) : 예외, 입출력, 이벤트 등이 발생하여 현재 실행중인 프로세스를 준비상태로 바꾸고, 해당 작업을 먼저 처리하는 것
- 입출력 또는 이벤트 대기 (I/O or Event wait) : 실행중인 프로세스가 입출력이나 이벤트를 처리해야하는 경우, 입출력/이벤트가 모두 끝날 때까지 대기상태로 만드는 것
- 입출력 또는 이벤트 완료 (I/O or Event Completion) : 입출력/이벤트가 끝난 프로세스를 준비상태로 전환하여 스케줄러에 의해 선택될 수 있도록 만드는 것

## **CPU 스케줄링의 종류**

### **비선점 스케줄링**

- FCFS (First Come First Served)
    - 큐에 도착한 순서대로 CPU 할당
    - 실행시간이 짧은게 뒤로가면 평균 대기시간이 길어진다.
- SJF (Shortest Job First)
    - 수행시간이 가장 짧다고 판단되는 작업을 먼저 수행
    - FCFS 보다 평균 대기 시간 감소, 짧은 작업에 유리

### **선점 스케줄링**

- Priority Sceduling
    - 정적/동적으로 우선순위를 부여하여 우선순위가 높은 순서대로 처리
    - 우선순위가 낮은 프로세스가 무한정 기다리는 Starvation(기하 현상)이 생길 수 있다.
    - Aging 방법으로 Starvation 문제 해결 가능
- Round Robin
    - FCFS에 의해 프로세스들이 보내지면 각 프로세스는 동일한 시간의 `Time Quantum`만큼 CPU를 할당받는다.
    - `Time Quantum` or `Time Slice` : 실행의 최소단위 시간
    - 할당시간 (Time Quantum)이 크면 FCFS와 같게되고, 작으면 문맥교환 (Context Switching)이 잦아져서 오버헤드가 증가한다.
- Multilevel Queue (다단계 큐)
    - 작업들을 여러 종류의 그룹으로 나누어 여러개의 큐를 이용하는 기법
    - 우선순위가 낮은 큐들이 실행 못하는 것을 방지하고자 각 큐마다 다른 타임 퀀텀을 설정해주는 방식 사용
    - 우선순위 높은 큐는 작은 타임 퀀텀 할당, 우선순위 낮은 큐는 큰 타임퀀텀 할당

## **데드락 (DeadLock)**

프로세스가 자원을 얻지 못해서 다음 처리를 하지 못하고 무한정 대기하는 상태. 교착상태라고도 부름시스템적으로 한정된 자원을 여러 곳에서 사용하고자 할 때 발생

## **데드락 발생조건**

4가지 모두 성립해야 데드락 발생! (하나라도 성립하지 않으면 데드락 문제 해결 가능)

1. **상호배제 (Mutual Exclusion)**

자원은 한번에 한 프로세스만 사용할 수 있다.

2. **점유 대기 (Hold and Wait)**

최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용되고있는 자원을 추가로 점유하기 위해 대기하는 프로세스가 존재해야한다.

3. **비선점 (Non preemptive)**

다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없다.

4. **순환대기 (Circular Wait)**

프로세스의 집합에서 순환형태로 자원을 대기하고 있어야한다.

## **데드락 처리**

교착 상태를 **예방 & 회피**

예방

교착 상태 발생 조건 중 하나를 제거하면서 해결 (자원 낭비 심함)

회피

교착 상태 발생시 피해나가는 방법ex) 은행원 알고리즘

## **세마포어**

공유된 자원에 여러 프로세스 혹은 스레드가 동시에 접근하면서 문제가 발생할 수 있다. 이때 공유된 자원의 데이터는 한번에 하나의 프로세스만 접근할 수 있도록 제한을 둬야한다. (상호배제)

이를 위해 나온 것이 바로 **세마포어**이다.

멀티프로그래밍 환경에서 공유자원에 대한 **접근을 제한하는 방법**프로세스 진입 여부를 **자원의 개수**를 통해 결정!

세마포어는 사용 중인 리소스를 잠그는 데 사용되는 보호된 변수 또는 추상 데이터 유형이다. 공유된 자원의 데이터를 여러 '프로세스'에서 접근하는 것을 막는다. 세마포어의 값은 공통 자원의 상태를 나타냅니다. 리소스 상태를 나타내는 간단한 카운터이다. 공유 리소스에 접근할 수 있는 프로세스의 최대 허용치만큼 동시에 사용자가 접근하여 사용할 수 있다.

## **임계구역 (Critical Section)**

여러 프로세스가 데이터를 공유하면서 수행될 때, **각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분**

공유 데이터를 여러 프로세스가 동시에 접근할 때 잘못된 결과를 만들 수 있기 때문에, 한 프로세스가 임계구역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야한다. (상호배제)

## **뮤텍스**

임계구역을 가진 스레드들의 실행시간이 서로 겹치지 않고 각각 단독으로 실행되게 하는 기술 - 즉 공유자원에 대한 접근이 동시에 여러 스레드에서 일어나지 않도록 하는 것 = 상호배제

상호 배제 (Mutual Exclusion)의 약자

해당 접근을 조율하기 위해 lock과 unlock을 사용

- lock : 현재 임계구역에 들어갈 권한을 얻어옴 (만약 다른 프로세스/스레드가 임계구역 수행중이면 종료할 때까지 대기)
- unlock : 현재 임계구역을 모두 사용했음을 알림 (대기중인 다른 프로세스/스레드가 임계구역에 진입할 수 있음)

프로세스 혹은 스레드 간의 통신 시에 shared memory 등을 쓰는 경우 하나의 자원에 두 개 이상의 프로세스 혹은 스레드가 접근하는 경우에 문제가 발생한다. 이를 제어하기 위해 스레드는 뮤 텍스를 사용하고, 프로세스에서는 세마포어를 사용한다.

- 뮤 텍스 : 상호 배제라고도 하며, Critical Section을 가진 스레드의 Running Time이 서로 겹치지 않도록 각각 단독으로 실행하게 하는 기술이다. 뮤 텍스는 상태가 0, 1 두 개뿐인 이진 세마포어. synchronized 또는 lock을 통해 해결한다.

## **뮤텍스 세마포어 정리**

세마포어는 자원의 개수로 임계구역 진입조건을 판단하고,뮤텍스는 락과 언락연산을 통해 임계구역 진입 조건을 판단한다.

가장 큰 차이는 동기화 대상의 개수이다. **뮤 텍스는 동기화 대상이 하나**
뿐이고, **세마포어는 동기화 대상이 하나 이상** 일 때.

## **메모리**

> 기억장치. 각각의 주소를 가진 대용량의 바이트 배열.
> 

CPU는 메모리에서 불러와서 연산작업들을 하는데, 다음과 같다.

1. PC가 가리키는 연산을 fecth
2. 그 연산을 decode(해석)하여 관련된 다른 피연산자를 메모리에서 fetch 할수도 있다.
3. 가져온 피연산자에 대한 연산이 실행되면, 결과는 다시 메모리에 저장(store)된다.

## 프로세스의 메모리 접근

- 각 프로세스가 메모리의 주소공간을 별도로 관리할 수 있는게 멀티 프로그래밍
- 각 프로세스는 할당된 메모리 주소에 base resgister(시작) & limit register(끝)을 통해 접근할 수 있음

메모리 주소공간

- base register 보다 크거나 같고, base + limit register보다 작을때 접근권한을 가지고,
- 이 외의 주소공간을 접근할려고하면 segmentation fault 에러를 발생시킨다.

## 프로세스 주소 할당(Address Binding)

프로그램은 실행 가능한 binary 파일형태로 disk에 존재한다. 프로그램을 실행시키기위해 프로그램을 메모리로 옮겨진다. 이 때 실행을 위해 메모리로 옮겨지기 전 프로세스들은 **Input Queue**에서 대기한다.

- Input Queue에서 프로세스 하나 선택해서 메모리에 적재한다.
- 프로세스가 실행되면, 메모리의 연산과 데이터들을 접근한다.
- 프로세스가 종료되면, 프로세스가 사용하던 메모리 영역을 해제하고 다시 사용 가능해진다.

### 주소 할당의 일련의 과정은 아래와 같이 이루어진다.

1. O/S커널이 실행된 프로그램의 주소의 할당
2. 프로세스 내 Symbolic address를 컴파일러가 relocatable address로 할당
3. 그 후 linker나 loader 이러한 relocatable address를 absolute address(절대 주소)로 할당한다.

**주소할당순서 그림**

![https://blog.kakaocdn.net/dn/Ffcqm/btrp1INiNNC/759sce6smvCQw6uSsWreHK/img.png](https://blog.kakaocdn.net/dn/Ffcqm/btrp1INiNNC/759sce6smvCQw6uSsWreHK/img.png)

- source program 단계에선 symbolic address를 가짐
- 컴파일 단계를 거치며, relocatable address로 할당
- linker에 의해 logical address 할당
- 실제로 메모리에 로드될때 physical address를 할당받음

## Logical(논리) vs Physical(물리) Address Space

- 논리 주소(logical address): CPU가 사용하고 있는 주소. 물리주소와는 상관 없음.
- 물리 주소(Pyhsical address): 실제로 메모리에 로드되어있는 주소.

## MMU(Memory Management Unit)

: 논리 주소를 물리주소로 변경하여 연결시켜주는 하드웨어 디바이스.

![https://blog.kakaocdn.net/dn/bLZhRQ/btrpQRFEKOa/xFxdCHQiGHkeZRQXYEo4k0/img.png](https://blog.kakaocdn.net/dn/bLZhRQ/btrpQRFEKOa/xFxdCHQiGHkeZRQXYEo4k0/img.png)

- relocation register: MMU의 base register
    - 실제 변수 a의 물리적 주소가 14346일때, logical 주소 346을 주면 MMU를 거쳐서 14346으로 변경되고 그에 따른 연산처리를 해줌

## 유동적인 로딩(Dynamic Loading)

- 메모리 주소공간을 효율적으로 사용하기위해 파일전체를 로드하는 것이 아닌 필요한 것만 그때 로드하는 것.
- relocatable linking loader가 필요할때만 address table에 반영해준다.

## Dynamic Linking and Shared Libraries

- static linking(정적 연결): 컴파일 시점에서 라이브러리 링커에 의해 연결되어 실행 파일의 일부분이 됨.
- dynamic linking(동적 연결): 해당 라이브러리를 사용할때 연결하여 사용. static linking과 다르게 주소를 참조하여 사용.

## 연속 메모리 할당(Contiguous Memory Allocation)

- 프로세스를 메모리에 할당하는 방식
- 싱글 섹션 메모리를 가진다.
- 위에서 봤던 basic과 limit register로 프로세스의 메모리 할당 범위를 확인하고,
- MMU내의 relocation register에 의해 물리주소와 매칭됨.

### 메모리 할당

**variable-partition :** 각 파티션에 하나의 프로세스만 적재하는 방법.

![https://blog.kakaocdn.net/dn/ezQRoY/btrp6ydmugK/bCKJBRICRtKJq21n22uHP0/img.png](https://blog.kakaocdn.net/dn/ezQRoY/btrp6ydmugK/bCKJBRICRtKJq21n22uHP0/img.png)

이렇게 할당하고 사용 후 해제하다보면

빈 공간(파란색 부분) **hole**[5](https://cano721.tistory.com/15#footnote_15_5)이 발생

### 이런 여러 hole이 있을때 메모리 할당하는 방법

- First-Fit: 할당할 수 있는 크기의 첫번째 hole에 할당
- Best-Fit: 가장 작은 곳부터 할당
- Worst-Fit: 가장 큰 곳부터 할당

## 단편화(Fragmentation)

- 외부단편화(external fragmentation)
    - 연속 메모리 할당에서 나타나는 현상
    - 작업에 충분한 메모리 공간이 남아있지만, 남은 빈공간의 크기들이 작업 사이즈보단 작아서 실제론 이용이 불가능한 상태
- 내부단편화(internal fragmentation)
    - 페이징 시에 나타나는 현상
    - 각각의 공간에서 작업을 위해 사용하고 남은 공간을 뜻함.(낭비)

## 

## 질문

**Q. 페이지 폴트, Page Fault가 무엇인가?**

**A. 가상 메모리의 페이지(논리 메모리) 테이블에는 페이지가 Main Memory에 있는지, Swap area(Disk)에 있는지 표시하는 Valid bit를 사용한다.**

- **> 0이면 디스크에 있고, 1이면 메모리에 있다는 뜻이다.**

**프로세스가 페이지를 요청(demand)했을 때 그 페이지가 메모리에 없는 경우를 페이지 폴트라고 한다.**

**페이지 폴트가 발생하면 프레임(물리 메모리)을 새로 할당 받아야 하며,**

**프로세스가 해당 페이지를 사용할 수 있도록 스왑 영역에서 메인 메모리로 옮겨야 한다.**

**그리고 페이지 테이블을 재구성 하고, 프로세스의 작업을 재 시작한다.**  


**Q. 요구 페이징, Demand Paging이 무엇인가?**

**A. 요구 페이징은 페이징 기법을 토대로 프로세스의 일부 페이지들만 메모리에 적재하고**

**나머지는 하드 디스크에 두며, 페이지가 필요할 때 메모리를 할당받고 페이지를 적재시키는**

**메모리 관리 기법을 말한다.**

**여기서 Demand의 의미는 페이지가 필요할 때까지는 물리 메모리에 적재하지 않는다는 말이다.**

**Demand를 해야 메인 메모리에 적재시키는 것이다.**

**만약 Demand를 했을 때 메인 메모리가 부족하게 되면 Page Replacement가 일어난다.**  


**Q. 페이지 테이블은 어떻게 구성되어 있는가?**

**1. Valid bit**

- **> 페이지가 메모리에 적재되어 있는지를 나타냄 (0: 스왑 영역, 1: 메인 메모리)**

**2. dirty bit**

- **> 페이지가 메모리에 적재된 후 수정되었는지 (0 : 수정 x , 1 : 수정 o)**

**3. Physical Address field**

- **> 페이지가 메모리에 적재되어있을 경우 물리 프레임 번호가 기록됨**
- **> 페이지가 메모리에 없을 경우 디스크 주소(디스크 블록 번호)가 기록됨**  


**Q. 메모리가 어떻게 구성되어 있는지 설명해 주세요.**

**A. 메모리는 크게 코드, 데이터, 스택, 힙 영역으로 나누어져 있다.**

**코드 영역은 실행될 프로그램의 코드가 저장되어 있는 영역이다.**

**데이터 영역은 전역 변수(global)와 정적(static) 변수 그리고 리터럴값이 저장되어 있는 영역이다.**

**스택 영역은 지역변수(local)와 매개 변수(parameter)가 저장되어 있으며 함수의 호출과 함께 할당되는 영역이다.**

**힙 영역은 사용자에 의해 동적으로 할당되고 해제될 수 있는 메모리 영역이다.**

**스택 영역은 컴파일 타임에 크기가 결정되고, 힙 영역은 런 타임에 크기가 결정된다.**  


**Q. 캐시의 원리**

**A. 캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목 현상을 줄이기 위한 메모리이다.**

- **> CPU 속도와 메모리 Load/Read/Write의 차이**

**이러한 역할을 수행하기 위해서는 CPU 가 어떤 데이터를 원할 것인가를 어느 정도 예측할 수 있어야 한다.**

**캐시의 성능은 작은 용량의 캐시 메모리에 CPU 가 이후에 참조할, 쓸모 있는 정보가 어느 정도 들어있느냐에 따라 좌우되기 때문이다.**

- **> Cache Miss가 많으면 캐시가 쓸모 없음**

**이 때 적중률(Hit rate)을 극대화 시키기 위해 데이터 지역성(Locality)의 원리를 사용한다.**  
  
  

**Q. 페이지 교체, Page Replacement란 무엇인지 설명하시오.**

**페이지 교체는 페이지 부재(page fault)가 발생하면**

**메인 메모리에 있으면서 사용하지 않는 페이지를 디스크(Swap Area)로 내보내고 새로운 페이지로 바꾸는 과정이다.**

- **> page fault handler가 담당함.**
- *** 페이지 교체의 목표는 현재 작업 집합에 포함되지 않거나 가까운 미래에 참조되지 않을 페이지를 Swap-Area로 내려 페이지 폴트의 횟수를 줄이는 것이다.**

**내보낼 페이지를 고를 때는 시스템의 효율성에 영향을 주므로 페이지 부재 비율이 가장 낮은 알고리즘을 선택한다.**

**대표적인 알고리즘**

**LRU(Least Recently Used)**

**LRU 알고리즘은 실제메모리의 페이지들 중에서 가장 오랫동안 사용되지 않은 페이지를 선택하는 방식으로 많이 사용되고 있다.**  


**Q. 단편화의 종류와 발생하는 이유는?**

**A. 페이징은 프로세스가 차지하는 물리적 메모리 공간이 비연속적이 되도록 허용하는 메모리 관리 기법을 말한다.**

**(논리적으로는 연속됨)**

**페이징은 외부 단편화가 발생하지 않으며, 따라서 별도의 압축 과정이 필요하지 않다.**

**페이징 기법을 사용할 때, 외부 단편화는 발생하지 않는다.**

**모든 사용 가능한 프레임은 그것을 필요로 하는 프로세스에게 할당될 수 있기 때문이다.**

**하지만 내부 단편화가 발생할 수 있다는 단점이 있다.**

**프레임(물리적 메모리)은 일정한 크기로 할당되기 때문이다.**

**그러나 내부 단편화를 위해 페이지의 크기를 작게 만든다고 해도 총 페이지의 갯수가 그만큼 늘어나기 때문에 페이지를 관리하는 오버헤드 또한 증가하게 된다.**  
  
**Q. Page의 크기가 커질 경우, 작아질 경우 어떻게 되는가?**

**Page 크기는 보통 1~4KB의 용량을 가진다.**

![https://blog.kakaocdn.net/dn/cLC2rP/btrlSwxoWy3/s5a7Eynn4fLVSYGQCiXwkk/img.png](https://blog.kakaocdn.net/dn/cLC2rP/btrlSwxoWy3/s5a7Eynn4fLVSYGQCiXwkk/img.png)

**페이지 크기가 작아지면**

**장점**

**1. 페이지 단편화가 감소되고, 한 개의 페이지를 주기억장치로 이동하는 시간이 줄어든다.**

**2. 불필요한 내용이 주기억장치에 적재될 확률이 적어서 효율적인 워킹 셋을 유지할 수 있음**

**3. Locality에 더 알맞아 기억장치 효율이 높아짐**

**단점**

**1. 페이지 맵 테이블의 크기가 커지고, 매핑속도가 느려짐**

**2. 디스크 접근 횟수가 많아져 전체적 I/O 시간이 늘어남**

**페이지 크기가 커진다면**

**장점**

**1. 페이지 정보를 갖는 페이지 맵 테이블의 크기가 작아지고 매핑 속도는 빨라진다.**

**2. 디스크 접근 횟수가 줄어들어 I/O 시간이 줄어든다.**

**단점**

**1. 페이지 단편화가 증가하는 경향이 있고, 한 개의 페이지 자체가 주기억장치로 이동하는 시간이 늘어난다.**

**2. 불필요한 내용까지도 적재되는 경우가 있다.**

**Q. 프로그램 실행 초기에는 모두 page fault 가 날 것이다. 어떻게 하는가?**

**Prepaging이라는 기법이 있다.**

**처음에 과도한 page fault를 방지하기 위해 프로그램 초기에 필요할 것 같은 모든 페이지를 한꺼번에 페이지 프레임에 적재하는 기법이다.**

- **> 다만 잘못 사용하면 사용하지도 않을 페이지들을 적재하여 비효율을 초래할 수도 있다.**

참고사이트

[https://hyonee.tistory.com/95](https://hyonee.tistory.com/95)

[https://dev-coco.tistory.com/162](https://dev-coco.tistory.com/162)

[https://mangkyu.tistory.com/92](https://mangkyu.tistory.com/92)

[https://velog.io/@syleemk/면접-대비-운영체제](https://velog.io/@syleemk/%EB%A9%B4%EC%A0%91-%EB%8C%80%EB%B9%84-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C)

[https://minhamina.tistory.com/235](https://minhamina.tistory.com/235)

[https://luv-n-interest.tistory.com/1168](https://luv-n-interest.tistory.com/1168)

[https://cano721.tistory.com/15](https://cano721.tistory.com/15)

